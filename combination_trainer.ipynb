{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irong/dlenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#clear all variables\n",
    "%reset -f\n",
    "\n",
    "from class_and_functions_for_combinations import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "dir_names = ['tmp', 'tmp/dss', 'tmp/evals', 'tmp/hes', 'tmp/models', 'tmp/real_dss/', 'tmp/training_combinations/']\n",
    "for dir_name in dir_names:\n",
    "    if not os.path.exists(dir_name):\n",
    "        print('creating directory: ', dir_name)\n",
    "        os.makedirs(dir_name)\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############\n",
    "# architecture_vars = ['a']\n",
    "# droput_vars = [0.3]\n",
    "\n",
    "# steer_noise_level_vars = [0, 3, 6, 9, 12, 14, 16]\n",
    "# he_distance_vars = [0.4, 0.6, 0.8]\n",
    "\n",
    "# canny1_vars = [100]\n",
    "# canny2_vars = [200]\n",
    "# blur_vars = [3]\n",
    "# img_noise_vars = [80]\n",
    "# keep_bottom_vars = [2/3, 0.9]\n",
    "# ds_length_vars = [5000, 1000]\n",
    "# img_size_vars = [32]\n",
    "\n",
    "# batch_size_vars = [65536]\n",
    "# lr_vars = [0.3, 0.03, 0.003]\n",
    "# epochs_vars = [100, 300, 900]\n",
    "# L1_lambda_vars = [1e-3, 1e-4]\n",
    "# L2_lambda_vars = [1e-1, 1e-2]\n",
    "# weight_decay_vars = [9e-5, 9e-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "architecture_vars = ['a']\n",
    "droput_vars = [0.3]\n",
    "\n",
    "steer_noise_level_vars = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "he_distance_vars = [.1,.2,.3,.4,.5,.6,.7,.8,.9]\n",
    "\n",
    "canny1_vars = [100]\n",
    "canny2_vars = [200]\n",
    "blur_vars = [3]\n",
    "img_noise_vars = [80]\n",
    "keep_bottom_vars = [.8]#[.4,.5,.6,.7,.8,.9]\n",
    "ds_length_vars = [10000]\n",
    "img_size_vars = [32]\n",
    "\n",
    "batch_size_vars = [65536]\n",
    "lr_vars = [0.003]\n",
    "epochs_vars = [100,300,1000]\n",
    "L1_lambda_vars = [1e-4]\n",
    "L2_lambda_vars = [1e-2]\n",
    "weight_decay_vars = [9e-5] #5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total dataset combinations: 99\n",
      "number of unique names: 99, number of names: 99\n"
     ]
    }
   ],
   "source": [
    "#generate datasets and save them in tmp folder\n",
    "#names and parameters\n",
    "datasets = []\n",
    "for steer_noise_level in steer_noise_level_vars:\n",
    "    for he_distance in he_distance_vars:\n",
    "        for canny1, canny2 in zip(canny1_vars, canny2_vars):\n",
    "            for blur in blur_vars:\n",
    "                for img_noise in img_noise_vars:\n",
    "                    for keep_bottom in keep_bottom_vars:\n",
    "                        for img_size in img_size_vars:\n",
    "                            for ds_length in ds_length_vars:\n",
    "                                name = f'ds_sn{steer_noise_level:.0f}_he{100*he_distance:.0f}_canny{canny1}_{canny2}_blur{blur:.0f}_noise{img_noise:.0f}_keep{100*keep_bottom:.0f}_size{img_size:.0f}_length{ds_length:.0f}'\n",
    "                                params = {'name':name, 'steer_noise_level': steer_noise_level, 'he_distance': he_distance, 'canny1': canny1, 'canny2': canny2, 'blur': blur, 'img_noise': img_noise, 'keep_bottom': keep_bottom, 'img_size': img_size, 'ds_length': ds_length}\n",
    "                                datasets.append(params)\n",
    "\n",
    "print(f'total dataset combinations: {len(datasets)}')\n",
    "\n",
    "all_names = []\n",
    "for ds in datasets:\n",
    "    all_names.append(ds['name'])\n",
    "#check if there are duplicates\n",
    "print(f'number of unique names: {len(set(all_names))}, number of names: {len(all_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated and saved tmp/hes/hes_4_30.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/99 [00:20<01:14,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated and saved tmp/hes/hes_4_50.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/99 [00:30<01:49,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated and saved tmp/hes/hes_4_60.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/99 [00:40<02:38,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated and saved tmp/hes/hes_4_70.npz\n"
     ]
    }
   ],
   "source": [
    "# PREPARE DATASETS\n",
    "for ds in tqdm(datasets):\n",
    "    prepare_ds(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ANALYZE DATASETS VARIANCE\n",
    "# for ds in datasets:\n",
    "#     analyze_ds(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training combinations\n",
    "trainings_combinations = []\n",
    "for ds in datasets:\n",
    "    for architecture in architecture_vars:\n",
    "        for batch_size in batch_size_vars:\n",
    "            for lr in lr_vars:\n",
    "                for epochs in epochs_vars:\n",
    "                    for L1_lambda in L1_lambda_vars:\n",
    "                        for L2_lambda in L2_lambda_vars:\n",
    "                            for weight_decay in weight_decay_vars:\n",
    "                                for dropout in droput_vars:\n",
    "                                    name = f'tr_{ds[\"name\"]}_arch{architecture}_bs{batch_size:.0f}_lr{lr*10**6:.0f}_ep{epochs:.0f}_L1{L1_lambda*10**6:.0f}_L2{L2_lambda*10**6:.0f}_wd{weight_decay*10**6:.0f}_dr{dropout*100:.0f}'\n",
    "                                    params = {'name':name, 'ds_name': ds['name'], 'architecture': architecture, 'batch_size': batch_size, 'lr': lr, 'epochs': epochs, 'L1_lambda': L1_lambda, 'L2_lambda': L2_lambda, 'weight_decay': weight_decay, 'dropout': dropout}\n",
    "                                    trainings_combinations.append(params)\n",
    "\n",
    "all_names = []\n",
    "for tr in trainings_combinations:\n",
    "    all_names.append(tr['name'])\n",
    "#check if there are duplicates\n",
    "print(f'number of unique names: {len(set(all_names))}, number of names: {len(all_names)}')\n",
    "\n",
    "print(f'total training combinations: {len(trainings_combinations)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING \n",
    "for tr in tqdm(trainings_combinations):\n",
    "    train(tr, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "for tr in tqdm(trainings_combinations):\n",
    "    evaluate(tr, eval_datasets=ALL_EVALUATION_DATASETS, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEST result\n",
    "best_combination, best_MSE, all_MSE = get_best_result(trainings_combinations, eval_datasets=REAL_EVALUATION_DATASETS, device=device)\n",
    "\n",
    "#plot mses\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# ax.scatter(np.arange(len(all_MSE)), all_MSE)\n",
    "ax.plot(np.arange(len(all_MSE)), all_MSE)\n",
    "ax.set_xlabel('dataset')\n",
    "ax.set_ylabel('MSE')\n",
    "#y limits\n",
    "# ax.set_ylim(0, 0.2)\n",
    "plt.show()\n",
    "\n",
    "print(f'best combination: {best_combination}, best MSE: {best_MSE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEST result\n",
    "best_combination, best_MSE, all_MSE = get_best_result(trainings_combinations, eval_datasets=REAL_CLEAN_DATASETS, device=device)\n",
    "\n",
    "#plot mses\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# ax.scatter(np.arange(len(all_MSE)), all_MSE)\n",
    "ax.plot(np.arange(len(all_MSE)), all_MSE)\n",
    "ax.set_xlabel('dataset')\n",
    "ax.set_ylabel('MSE')\n",
    "#y limits\n",
    "# ax.set_ylim(0, 0.2)\n",
    "plt.show()\n",
    "\n",
    "print(f'best combination: {best_combination}, best MSE: {best_MSE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEST result\n",
    "best_combination, best_MSE, all_MSE = get_best_result(trainings_combinations, eval_datasets=REAL_NOISY_DATASETS, device=device)\n",
    "\n",
    "#plot mses\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# ax.scatter(np.arange(len(all_MSE)), all_MSE)\n",
    "ax.plot(np.arange(len(all_MSE)), all_MSE)\n",
    "ax.set_xlabel('dataset')\n",
    "ax.set_ylabel('MSE')\n",
    "#y limits\n",
    "# ax.set_ylim(0, 0.2)\n",
    "plt.show()\n",
    "\n",
    "print(f'best combination: {best_combination}, best MSE: {best_MSE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEST result\n",
    "best_combination, best_MSE, all_MSE = get_best_result(trainings_combinations, eval_datasets=ALL_EVALUATION_DATASETS, device=device)\n",
    "\n",
    "#plot mses\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# ax.scatter(np.arange(len(all_MSE)), all_MSE)\n",
    "ax.plot(np.arange(len(all_MSE)), all_MSE)\n",
    "ax.set_xlabel('dataset')\n",
    "ax.set_ylabel('MSE')\n",
    "#y limits\n",
    "# ax.set_ylim(0, 0.2)\n",
    "plt.show()\n",
    "\n",
    "print(f'best combination: {best_combination}, best MSE: {best_MSE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEST result\n",
    "best_combination, best_MSE, all_MSE = get_best_result(trainings_combinations, eval_datasets=SIM_EVALUATION_DATASETS, device=device)\n",
    "\n",
    "#plot mses\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# ax.scatter(np.arange(len(all_MSE)), all_MSE)\n",
    "ax.plot(np.arange(len(all_MSE)), all_MSE)\n",
    "ax.set_xlabel('dataset')\n",
    "ax.set_ylabel('MSE')\n",
    "#y limits\n",
    "# ax.set_ylim(0, 0.2)\n",
    "plt.show()\n",
    "\n",
    "print(f'best combination: {best_combination}, best MSE: {best_MSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best combination: {'name': 'tr_ds_sn5_he40_canny100_200_blur3_noise80_keep67_size32_length1000_archa_bs65536_lr30000_ep300_L1100_L210000_wd90_dr30', 'ds_name': 'ds_sn5_he40_canny100_200_blur3_noise80_keep67_size32_length1000', 'architecture': 'a', 'batch_size': 65536, 'lr': 0.03, 'epochs': 300, 'L1_lambda': 0.0001, 'L2_lambda': 0.01, 'weight_decay': 9e-05, 'dropout': 0.3}, best MSE: 0.036422715537554835"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for steer_noise_level\n",
    "steer_noise_level_MSEs = get_MSEs_for('steer_noise_level', trainings_combinations, eval_datasets=REAL_EVALUATION_DATASETS)\n",
    "print(steer_noise_level_MSEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for he_distance\n",
    "he_distance_MSEs = get_MSEs_for('he_distance', trainings_combinations, eval_datasets=REAL_EVALUATION_DATASETS)\n",
    "print(he_distance_MSEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for lr\n",
    "lr_MSEs = get_MSEs_for('lr', trainings_combinations, eval_datasets=REAL_EVALUATION_DATASETS)\n",
    "print(lr_MSEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for epochs\n",
    "epochs_MSEs = get_MSEs_for('epochs', trainings_combinations, eval_datasets=REAL_EVALUATION_DATASETS)\n",
    "print(epochs_MSEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! CLEARING DATA !!!\n",
    "import shutil\n",
    "import os\n",
    "folders = ['dss', 'evals', 'hes', 'models', 'real_dss', 'to_del', 'training_combinations']\n",
    "folders = ['to_del']\n",
    "for folder in folders:\n",
    "    folder_path = f'tmp/{folder}'\n",
    "    shutil.rmtree(folder_path)\n",
    "    os.mkdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testN = HEstimator()\n",
    "# a = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "# print(testN)\n",
    "# print(a)\n",
    "# np.savez('testN', testN=testN, a=a)\n",
    "import numpy as np\n",
    "loadedN = np.load('testN.npz', allow_pickle=True)['testN']\n",
    "loadeda = np.load('testN.npz', allow_pickle=True)['a']\n",
    "print(loadedN)\n",
    "print(loadeda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_keeper_ahead = HEstimator()\n",
    "lane_keeper_ahead.to(device)\n",
    "\n",
    "name_dataset = 'ds_sn30_he40_canny100_200_blur3_noise80_keep67_size32_length10000' #'saved_tests/train18' #'saved_tests/sim_dataset0'\n",
    "#create dataset #takes a long time but then training is faster\n",
    "train_dataset = MyDataset(name_dataset, device=device)\n",
    "\n",
    "#split dataset into train and val\n",
    "train_size = int(0.9*len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# DATALOADERS\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8*8192, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8192, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING \n",
    "#parameters\n",
    "lr = 0.003 #0.005\n",
    "epochs = 100 #500\n",
    "#regularization is applied only to convolutional section, add weight decay to apply it to all layers\n",
    "L1_lambda = 1e-4 #9e-4\n",
    "L2_lambda = 1e-2 #1e-2\n",
    "optimizer = torch.optim.Adam(lane_keeper_ahead.parameters(), lr=lr, weight_decay=9e-5) #wd = 2e-3# 3e-5\n",
    "regr_loss_fn1 = nn.MSELoss() #before epochs/2\n",
    "regr_loss_fn2 = nn.MSELoss() #after epochs/2 for finetuning\n",
    "\n",
    "best_val = 100\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # try:\n",
    "    if True:\n",
    "        regr_loss_fn = regr_loss_fn1 if epoch < epochs//2 else regr_loss_fn2\n",
    "        he_loss = train_epoch(lane_keeper_ahead, train_dataloader, regr_loss_fn, optimizer, L1_lambda, L2_lambda)\n",
    "        val_he_loss = val_epoch(lane_keeper_ahead, val_dataloader, regr_loss_fn)\n",
    "        clear_output(wait=False)\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    #     torch.cuda.empty_cache()\n",
    "    #     continue\n",
    "    if val_he_loss < best_val:\n",
    "        best_val = val_he_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(lane_keeper_ahead.state_dict(), model_name)\n",
    "        print(\"model saved\")\n",
    "    \n",
    "    print(f\"Epoch  {epoch+1}/{epochs},  loss = {regr_loss_fn} \\nhe_loss: {he_loss:.4f},   Val: {val_he_loss:.4f}, best_val: {best_val:.4f}, best_epoch: {best_epoch}\")\n",
    "    # print(f\"lat_err_loss2: {err_loss2:.4f},   Val: {val_loss2:.4f}\")\n",
    "    # print(f\"curv_loss: {curv_loss}\")\n",
    "\n",
    "#Note: sweet spot for training is around 0.016 -> 0.020, also note that training can get stuck, and loss can start improving randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE ON TEST SET (UNSEEN DATA)\n",
    "lane_keeper_ahead.load_state_dict(torch.load(model_name))\n",
    "he_loss = val_epoch(lane_keeper_ahead, val_dataloader, regr_loss_fn)\n",
    "\n",
    "# print(f\"lateral_err2_loss: {err_loss2}\")\n",
    "print(f\"he loss: {he_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE CONVOLUTIONAL FILTERS\n",
    "conv_layers = []\n",
    "children = list(lane_keeper_ahead.children())\n",
    "for i in range(len(children)):\n",
    "    if isinstance(children[i], nn.Conv2d):\n",
    "        conv_layers.append(children[i])\n",
    "    elif isinstance(children[i], nn.Sequential):\n",
    "        for child in children[i].children():\n",
    "            if isinstance(child, nn.Conv2d):\n",
    "                conv_layers.append(child)\n",
    "\n",
    "c0 = conv_layers[0].weight.data.cpu().numpy()\n",
    "c1 = conv_layers[1].weight.data.cpu().numpy()\n",
    "c2 = conv_layers[2].weight.data.cpu().numpy()\n",
    "\n",
    "def plot_nchw_data(data, h_num, v_num, title, size=(10, 10)):\n",
    "    fig, axs = plt.subplots(h_num, v_num, figsize=size)\n",
    "    shape = data.shape\n",
    "    data = data.reshape(shape[0]*shape[1], shape[2], shape[3])\n",
    "    for idx, ax in enumerate(axs.flatten()):\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if idx < len(data):\n",
    "            ax.imshow(data[idx,:,:], cmap='gray')\n",
    "    plt.suptitle(title)\n",
    "    #plt.tight_layout(rect=[0, 0, 1, 0.97], h_pad=0, w_pad=0)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "# fig0 = plot_nchw_data(c0, 4, 4, 'conv0')\n",
    "print(c0.shape)\n",
    "print(c1.shape)\n",
    "print(c2.shape)\n",
    "\n",
    "fig0 = plot_nchw_data(c0, 1, 4, 'conv0', size=(8,2))\n",
    "\n",
    "fig1 = plot_nchw_data(c1, 4, 4, 'conv1', size=(5,5)) \n",
    "\n",
    "fig2 = plot_nchw_data(c2, 8, 8, 'conv2', size=(10,10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT TO ONNX MODEL FOR OPENCV\n",
    "lane_keeper_ahead.load_state_dict(torch.load(model_name))\n",
    "\n",
    "#save the model so that opencv can load it\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device('cpu')\n",
    "lane_keeper_ahead.to(device)\n",
    "\n",
    "# set the model to inference mode\n",
    "lane_keeper_ahead.eval()\n",
    "\n",
    "# Create some sample input in the shape this model expects \n",
    "# This is needed because the convertion forward pass the network once \n",
    "dummy_input = torch.randn(1, 1, 32, 32)\n",
    "torch.onnx.export(lane_keeper_ahead, dummy_input, onnx_lane_keeper_path, verbose=True)\n",
    "\n",
    "clear_output(wait=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "lane_keeper_ahead.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ff087476d859467207b75b86d772837aefc8c57842a4549d55b8593c8b8ca04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
