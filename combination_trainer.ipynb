{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irong/dlenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px # this is another plotting library for interactive plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, manifold # we will use the metrics and manifold learning modules from scikit-learn\n",
    "from pathlib import Path # to interact with file paths\n",
    "from PIL import Image # to interact with images\n",
    "from tqdm import tqdm # progress bar\n",
    "from pprint import pprint # pretty print (useful for a more readable print of objects like lists or dictionaries)\n",
    "from IPython.display import clear_output # to clear the output of the notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2 as cv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINITIONS\n",
    "IN, OUT, CONV_LAYERS, FC_LAYERS, DROPOUT = 'IN', 'OUT', 'CONV_LAYERS', 'FC_LAYERS', 'DROPOUT'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK ARCHITECTURE\n",
    "DROPOUT_PROB = 0.3\n",
    "DEFAULT_CONV_LAYERS = nn.Sequential( #in = 32x32\n",
    "            nn.Conv2d(1, 4, 5, 1), #out = 28\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=DROPOUT_PROB),\n",
    "            nn.MaxPool2d(2, 2), #out=14\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.Dropout(p=DROPOUT_PROB),\n",
    "            nn.Conv2d(4, 4, 5, 1), #out = 10\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=DROPOUT_PROB),\n",
    "            nn.MaxPool2d(2, 2), #out=5\n",
    "            nn.Dropout(p=DROPOUT_PROB),\n",
    "            nn.Conv2d(4, 32, 5, 1), #out = 1\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "DEFAULT_FC_LAYERS = nn.Sequential(\n",
    "            nn.Linear(1*1*32, 16),\n",
    "            nn.ReLU(True),\n",
    "            # nn.Tanh(),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "\n",
    "NET_PARAMS = {IN:32, OUT:1, CONV_LAYERS:DEFAULT_CONV_LAYERS, FC_LAYERS:DEFAULT_FC_LAYERS, DROPOUT:DROPOUT_PROB}\n",
    "\n",
    "\n",
    "class HEstimator(nn.Module):\n",
    "    def __init__(self, net_params=NET_PARAMS):\n",
    "        super().__init__()\n",
    "        self.conv = net_params[CONV_LAYERS]\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lin = net_params[FC_LAYERS]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE PREPROCESSING AND AUGMENTATION\n",
    "\n",
    "def preprocess_image(img, size=32, keep_bottom=0.66666667, canny1=100, canny2=200, blur=3):\n",
    "    \"\"\"\n",
    "    Preprocesses an image to be used as input for the network.\n",
    "    Note: the function modifies the image in place\n",
    "    \"\"\"\n",
    "    #set associated parameters to None to skip the step\n",
    "    skip_canny = canny1 == None or canny2 == None\n",
    "    skip_blur = blur == None\n",
    "    #check if its a valid image\n",
    "    assert len(img.shape) == 3 or len(img.shape) == 2, \"Invalid image shape\"\n",
    "    #check if the imge is grayscale\n",
    "    img_is_gray = len(img.shape) == 2\n",
    "    if not img_is_gray:\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    #cut the top part\n",
    "    img = img[int(img.shape[0]*(1-keep_bottom)):,:]\n",
    "    #resize 1\n",
    "    img = cv.resize(img, (2*size, 2*size))\n",
    "    #canny\n",
    "    if not skip_canny:\n",
    "        img = cv.Canny(img, canny1, canny2)\n",
    "    #blur\n",
    "    if not skip_blur:\n",
    "        img = cv.blur(img, (3,3), 0)\n",
    "    #resize 2\n",
    "    img = cv.resize(img, (size, size))\n",
    "    return img\n",
    "\n",
    "def augment_img(img):\n",
    "    \"\"\"\n",
    "    Augments an image by applying random transformations\n",
    "    Note: the function modifies the image in place\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    return img\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ff087476d859467207b75b86d772837aefc8c57842a4549d55b8593c8b8ca04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
