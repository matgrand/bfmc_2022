{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irong/dlenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px # this is another plotting library for interactive plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, manifold # we will use the metrics and manifold learning modules from scikit-learn\n",
    "from pathlib import Path # to interact with file paths\n",
    "from PIL import Image # to interact with images\n",
    "from tqdm import tqdm # progress bar\n",
    "from pprint import pprint # pretty print (useful for a more readable print of objects like lists or dictionaries)\n",
    "from IPython.display import clear_output # to clear the output of the notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2 as cv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINITIONS\n",
    "IN, OUT, CONV_LAYERS, FC_LAYERS, DROPOUT = 'IN', 'OUT', 'CONV_LAYERS', 'FC_LAYERS', 'DROPOUT'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK ARCHITECTURE\n",
    "DROPOUT_PROB = 0.3\n",
    "DEFAULT_CONV_LAYERS = nn.Sequential( #in = 32x32\n",
    "            nn.Conv2d(1, 4, 5, 1), #out = 28\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=DROPOUT_PROB),\n",
    "            nn.MaxPool2d(2, 2), #out=14\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.Dropout(p=DROPOUT_PROB),\n",
    "            nn.Conv2d(4, 4, 5, 1), #out = 10\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=DROPOUT_PROB),\n",
    "            nn.MaxPool2d(2, 2), #out=5\n",
    "            nn.Dropout(p=DROPOUT_PROB),\n",
    "            nn.Conv2d(4, 32, 5, 1), #out = 1\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "DEFAULT_FC_LAYERS = nn.Sequential(\n",
    "            nn.Linear(1*1*32, 16),\n",
    "            nn.ReLU(True),\n",
    "            # nn.Tanh(),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "\n",
    "NET_PARAMS = {IN:32, OUT:1, CONV_LAYERS:DEFAULT_CONV_LAYERS, FC_LAYERS:DEFAULT_FC_LAYERS, DROPOUT:DROPOUT_PROB}\n",
    "\n",
    "\n",
    "class HEstimator(nn.Module):\n",
    "    def __init__(self, net_params=NET_PARAMS):\n",
    "        super().__init__()\n",
    "        self.conv = net_params[CONV_LAYERS]\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lin = net_params[FC_LAYERS]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE PREPROCESSING AND AUGMENTATION\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "from time import time, sleep\n",
    "\n",
    "def preprocess_image(img, size=32, keep_bottom=0.66666667, canny1=100, canny2=200, blur=3):\n",
    "    \"\"\"\n",
    "    Preprocesses an image to be used as input for the network.\n",
    "    Note: the function modifies the image in place\n",
    "    \"\"\"\n",
    "    #set associated parameters to None to skip the step\n",
    "    skip_canny = canny1 == None or canny2 == None\n",
    "    skip_blur = blur == None\n",
    "    #check if its a valid image\n",
    "    assert len(img.shape) == 3 or len(img.shape) == 2, \"Invalid image shape\"\n",
    "    #check if the imge is grayscale\n",
    "    img_is_gray = len(img.shape) == 2\n",
    "    if not img_is_gray:\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    #cut the top part\n",
    "    img = img[int(img.shape[0]*(1-keep_bottom)):,:]\n",
    "    #resize 1\n",
    "    img = cv.resize(img, (2*size, 2*size))\n",
    "    #canny\n",
    "    if not skip_canny:\n",
    "        img = cv.Canny(img, canny1, canny2)\n",
    "    #blur\n",
    "    if not skip_blur:\n",
    "        img = cv.blur(img, (3,3), 0)\n",
    "    #resize 2\n",
    "    img = cv.resize(img, (size, size))\n",
    "    return img\n",
    "\n",
    "def augment_img(img, size=32, keep_bottom=0.66666667, canny1=100, canny2=200, blur=3, \n",
    "                max_tilt_fraction=0.1, noise_std=80):\n",
    "    \"\"\"\n",
    "    Augments an image by applying random transformations\n",
    "    Note: the function modifies the image in place\n",
    "    \"\"\"\n",
    "\n",
    "    # preaugmentation\n",
    "    img = cv.resize(img, (4*size, 4*size)) # 128x128\n",
    "\n",
    "    #create random ellipses to simulate light from the sun\n",
    "    light = np.zeros(img.shape, dtype=np.uint8)\n",
    "    #add ellipses\n",
    "    for j in range(2):\n",
    "        cent = (randint(0, img.shape[0]), randint(0, img.shape[1]))\n",
    "        axes_length = (randint(int(4*size/42.67),int(4*size/10.67)), randint(int(4*size/10.67), int(size*4/1.70))) #(randint(3, 12), randint(12, 75))\n",
    "        angle = randint(0, 360)\n",
    "        light = cv.ellipse(light, cent, axes_length, angle, 0, 360, 255, -1)\n",
    "    #create an image of random white and black pixels\n",
    "    light = cv.blur(light, (50,50))\n",
    "    noise = randint(0, 2, size=img.shape, dtype=np.uint8)*255\n",
    "    light = cv.subtract(light, noise)\n",
    "    light = np.clip(light, 0, 51)\n",
    "    light *= 5\n",
    "    #add light to the image\n",
    "    img = cv.add(img, light)\n",
    "\n",
    "    # dilation/erosion\n",
    "    r = randint(0, 5)\n",
    "    if r == 0:\n",
    "        #dilate\n",
    "        kernel = np.ones((randint(1, 5), randint(1, 5)), np.uint8)\n",
    "        img = cv.dilate(img, kernel, iterations=1)\n",
    "    elif r == 1:\n",
    "        #erode\n",
    "        kernel = np.ones((randint(1, 5), randint(1, 5)), np.uint8)\n",
    "        img = cv.erode(img, kernel, iterations=1)\n",
    "\n",
    "    #preprocessing\n",
    "    img = preprocess_image(img, size, keep_bottom, canny1, canny2, blur)\n",
    "\n",
    "    # second augmentation\n",
    "    #add random tilt\n",
    "    max_offset = int(size*max_tilt_fraction)\n",
    "    offset = randint(-max_offset, max_offset)\n",
    "    img = np.roll(img, offset, axis=0)\n",
    "    if offset > 0:\n",
    "        img[:offset, :] = 0 #randint(0,255)\n",
    "    elif offset < 0:\n",
    "        img[offset:, :] = 0 # randint(0,255)\n",
    "\n",
    "    #add noise \n",
    "    std = noise_std\n",
    "    std = randint(1, std)\n",
    "    noisem = randint(0, std, img.shape, dtype=np.uint8)\n",
    "    img = cv.subtract(img, noisem)\n",
    "    noisep = randint(0, std, img.shape, dtype=np.uint8)\n",
    "    img = cv.add(img, noisep)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATASET\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataset_file_path, he_distances=[0.5]):\n",
    "        self.data = []\n",
    "        path = path = np.load('sparcs/sparcs_path_precise.npy').T\n",
    "        log = np.load(dataset_file_path)\n",
    "        imgs, locs = log['imgs'],log['locs']\n",
    "        assert len(imgs) == len(locs), f'Invalid dataset, imgs and locs have different lengths: {len(imgs)} != {len(locs)}'\n",
    "        print(f'Dataset: {dataset_file_path}\\nDataset length: {len(imgs)}')\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        # The length of the dataset is simply the length of the self.data list\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.all_imgs[idx]\n",
    "        img = img.permute(2, 0, 1).float()\n",
    "        value = self.data[idx]\n",
    "        return img, value\n",
    "\n",
    "def create_dataset():\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ff087476d859467207b75b86d772837aefc8c57842a4549d55b8593c8b8ca04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
