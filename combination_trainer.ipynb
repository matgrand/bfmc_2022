{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear all variables\n",
    "%reset -f\n",
    "\n",
    "from class_and_functions_for_combinations import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL PARAMETERS\n",
    "# #architecture variations\n",
    "# architecture = 'a'\n",
    "# dropout = 0.5\n",
    "\n",
    "# #dataset variations\n",
    "# steer_noise_level = 15\n",
    "# he_distance = 0.5\n",
    "\n",
    "# #augmentation variations\n",
    "# canny1 = 100\n",
    "# canny2 = 200\n",
    "# blur = 3\n",
    "# img_noise = 80\n",
    "# keep_bottom = 0.66666667\n",
    "# ds_length = 10000\n",
    "# img_size = 32\n",
    "\n",
    "# #training variations\n",
    "# batch_size = 65536\n",
    "# lr = 0.003\n",
    "# epochs = 100\n",
    "# L1_lambda = 1e-4 \n",
    "# L2_lambda = 1e-2 \n",
    "\n",
    "#############\n",
    "architecture_vars = ['a']\n",
    "droput_vars = [0.3]\n",
    "\n",
    "steer_noise_level_vars = [0, 5, 10, 15, 20, 25, 30]\n",
    "he_distance_vars = [0.4, 0.6, 0.8]\n",
    "\n",
    "canny1_vars = [100]\n",
    "canny2_vars = [200]\n",
    "blur_vars = [3]\n",
    "img_noise_vars = [80]\n",
    "keep_bottom_vars = [2/3]\n",
    "ds_length_vars = [10000, 1000]\n",
    "img_size_vars = [32]\n",
    "\n",
    "batch_size_vars = [65536]\n",
    "lr_vars = [0.03, 0.003, 0.0003]\n",
    "epochs_vars = [100, 300]\n",
    "L1_lambda_vars = [1e-4]\n",
    "L2_lambda_vars = [1e-2]\n",
    "weight_decay_vars = [9e-3, 9e-4, 9e-5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate datasets and save them in tmp folder\n",
    "#names and parameters\n",
    "datasets = []\n",
    "for steer_noise_level in steer_noise_level_vars:\n",
    "    for he_distance in he_distance_vars:\n",
    "        for canny1, canny2 in zip(canny1_vars, canny2_vars):\n",
    "            for blur in blur_vars:\n",
    "                for img_noise in img_noise_vars:\n",
    "                    for keep_bottom in keep_bottom_vars:\n",
    "                        for img_size in img_size_vars:\n",
    "                            for ds_length in ds_length_vars:\n",
    "                                name = f'ds_sn{steer_noise_level:.0f}_he{100*he_distance:.0f}_canny{canny1}_{canny2}_blur{blur:.0f}_noise{img_noise:.0f}_keep{100*keep_bottom:.0f}_size{img_size:.0f}_length{ds_length:.0f}'\n",
    "                                params = {'name':name, 'steer_noise_level': steer_noise_level, 'he_distance': he_distance, 'canny1': canny1, 'canny2': canny2, 'blur': blur, 'img_noise': img_noise, 'keep_bottom': keep_bottom, 'img_size': img_size, 'ds_length': ds_length}\n",
    "                                datasets.append(params)\n",
    "\n",
    "print(f'total dataset combinations: {len(datasets)}')\n",
    "\n",
    "all_names = []\n",
    "for ds in datasets:\n",
    "    all_names.append(ds['name'])\n",
    "#check if there are duplicates\n",
    "print(f'number of unique names: {len(set(all_names))}, number of names: {len(all_names)}')\n",
    "\n",
    "for ds in tqdm(datasets):\n",
    "    prepare_ds(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training combinations\n",
    "trainings_combinations = []\n",
    "for ds in datasets:\n",
    "    for architecture in architecture_vars:\n",
    "        for batch_size in batch_size_vars:\n",
    "            for lr in lr_vars:\n",
    "                for epochs in epochs_vars:\n",
    "                    for L1_lambda in L1_lambda_vars:\n",
    "                        for L2_lambda in L2_lambda_vars:\n",
    "                            for weight_decay in weight_decay_vars:\n",
    "                                for dropout in droput_vars:\n",
    "                                    name = f'tr_{ds[\"name\"]}_arch{architecture}_bs{batch_size:.0f}_lr{lr*10**6:.0f}_ep{epochs:.0f}_L1{L1_lambda*10**6:.0f}_L2{L2_lambda*10**6:.0f}_wd{weight_decay*10**6:.0f}_dr{dropout*100:.0f}'\n",
    "                                    params = {'name':name, 'ds_name': ds['name'], 'architecture': architecture, 'batch_size': batch_size, 'lr': lr, 'epochs': epochs, 'L1_lambda': L1_lambda, 'L2_lambda': L2_lambda, 'weight_decay': weight_decay, 'dropout': dropout}\n",
    "                                    trainings_combinations.append(params)\n",
    "\n",
    "all_names = []\n",
    "for tr in trainings_combinations:\n",
    "    all_names.append(tr['name'])\n",
    "#check if there are duplicates\n",
    "print(f'number of unique names: {len(set(all_names))}, number of names: {len(all_names)}')\n",
    "\n",
    "print(f'total training combinations: {len(trainings_combinations)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING \n",
    "for tr in tqdm(trainings_combinations):\n",
    "    train(tr, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "for tr in tqdm(trainings_combinations):\n",
    "    mses = evaluate(tr, eval_datasets=DEFAULT_EVALUATION_DATASETS, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testN = HEstimator()\n",
    "# a = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "# print(testN)\n",
    "# print(a)\n",
    "# np.savez('testN', testN=testN, a=a)\n",
    "import numpy as np\n",
    "loadedN = np.load('testN.npz', allow_pickle=True)['testN']\n",
    "loadeda = np.load('testN.npz', allow_pickle=True)['a']\n",
    "print(loadedN)\n",
    "print(loadeda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_keeper_ahead = HEstimator()\n",
    "lane_keeper_ahead.to(device)\n",
    "\n",
    "name_dataset = 'ds_sn30_he40_canny100_200_blur3_noise80_keep67_size32_length10000' #'saved_tests/train18' #'saved_tests/sim_dataset0'\n",
    "#create dataset #takes a long time but then training is faster\n",
    "train_dataset = MyDataset(name_dataset, device=device)\n",
    "\n",
    "#split dataset into train and val\n",
    "train_size = int(0.9*len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# DATALOADERS\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8*8192, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8192, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING \n",
    "#parameters\n",
    "lr = 0.003 #0.005\n",
    "epochs = 100 #500\n",
    "#regularization is applied only to convolutional section, add weight decay to apply it to all layers\n",
    "L1_lambda = 1e-4 #9e-4\n",
    "L2_lambda = 1e-2 #1e-2\n",
    "optimizer = torch.optim.Adam(lane_keeper_ahead.parameters(), lr=lr, weight_decay=9e-5) #wd = 2e-3# 3e-5\n",
    "regr_loss_fn1 = nn.MSELoss() #before epochs/2\n",
    "regr_loss_fn2 = nn.MSELoss() #after epochs/2 for finetuning\n",
    "\n",
    "best_val = 100\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # try:\n",
    "    if True:\n",
    "        regr_loss_fn = regr_loss_fn1 if epoch < epochs//2 else regr_loss_fn2\n",
    "        he_loss = train_epoch(lane_keeper_ahead, train_dataloader, regr_loss_fn, optimizer, L1_lambda, L2_lambda)\n",
    "        val_he_loss = val_epoch(lane_keeper_ahead, val_dataloader, regr_loss_fn)\n",
    "        clear_output(wait=False)\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    #     torch.cuda.empty_cache()\n",
    "    #     continue\n",
    "    if val_he_loss < best_val:\n",
    "        best_val = val_he_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(lane_keeper_ahead.state_dict(), model_name)\n",
    "        print(\"model saved\")\n",
    "    \n",
    "    print(f\"Epoch  {epoch+1}/{epochs},  loss = {regr_loss_fn} \\nhe_loss: {he_loss:.4f},   Val: {val_he_loss:.4f}, best_val: {best_val:.4f}, best_epoch: {best_epoch}\")\n",
    "    # print(f\"lat_err_loss2: {err_loss2:.4f},   Val: {val_loss2:.4f}\")\n",
    "    # print(f\"curv_loss: {curv_loss}\")\n",
    "\n",
    "#Note: sweet spot for training is around 0.016 -> 0.020, also note that training can get stuck, and loss can start improving randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE ON TEST SET (UNSEEN DATA)\n",
    "lane_keeper_ahead.load_state_dict(torch.load(model_name))\n",
    "he_loss = val_epoch(lane_keeper_ahead, val_dataloader, regr_loss_fn)\n",
    "\n",
    "# print(f\"lateral_err2_loss: {err_loss2}\")\n",
    "print(f\"he loss: {he_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE CONVOLUTIONAL FILTERS\n",
    "conv_layers = []\n",
    "children = list(lane_keeper_ahead.children())\n",
    "for i in range(len(children)):\n",
    "    if isinstance(children[i], nn.Conv2d):\n",
    "        conv_layers.append(children[i])\n",
    "    elif isinstance(children[i], nn.Sequential):\n",
    "        for child in children[i].children():\n",
    "            if isinstance(child, nn.Conv2d):\n",
    "                conv_layers.append(child)\n",
    "\n",
    "c0 = conv_layers[0].weight.data.cpu().numpy()\n",
    "c1 = conv_layers[1].weight.data.cpu().numpy()\n",
    "c2 = conv_layers[2].weight.data.cpu().numpy()\n",
    "\n",
    "def plot_nchw_data(data, h_num, v_num, title, size=(10, 10)):\n",
    "    fig, axs = plt.subplots(h_num, v_num, figsize=size)\n",
    "    shape = data.shape\n",
    "    data = data.reshape(shape[0]*shape[1], shape[2], shape[3])\n",
    "    for idx, ax in enumerate(axs.flatten()):\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if idx < len(data):\n",
    "            ax.imshow(data[idx,:,:], cmap='gray')\n",
    "    plt.suptitle(title)\n",
    "    #plt.tight_layout(rect=[0, 0, 1, 0.97], h_pad=0, w_pad=0)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "# fig0 = plot_nchw_data(c0, 4, 4, 'conv0')\n",
    "print(c0.shape)\n",
    "print(c1.shape)\n",
    "print(c2.shape)\n",
    "\n",
    "fig0 = plot_nchw_data(c0, 1, 4, 'conv0', size=(8,2))\n",
    "\n",
    "fig1 = plot_nchw_data(c1, 4, 4, 'conv1', size=(5,5)) \n",
    "\n",
    "fig2 = plot_nchw_data(c2, 8, 8, 'conv2', size=(10,10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT TO ONNX MODEL FOR OPENCV\n",
    "lane_keeper_ahead.load_state_dict(torch.load(model_name))\n",
    "\n",
    "#save the model so that opencv can load it\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device('cpu')\n",
    "lane_keeper_ahead.to(device)\n",
    "\n",
    "# set the model to inference mode\n",
    "lane_keeper_ahead.eval()\n",
    "\n",
    "# Create some sample input in the shape this model expects \n",
    "# This is needed because the convertion forward pass the network once \n",
    "dummy_input = torch.randn(1, 1, 32, 32)\n",
    "torch.onnx.export(lane_keeper_ahead, dummy_input, onnx_lane_keeper_path, verbose=True)\n",
    "\n",
    "clear_output(wait=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "lane_keeper_ahead.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ff087476d859467207b75b86d772837aefc8c57842a4549d55b8593c8b8ca04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
