{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px # this is another plotting library for interactive plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, manifold # we will use the metrics and manifold learning modules from scikit-learn\n",
    "from pathlib import Path # to interact with file paths\n",
    "from PIL import Image # to interact with images\n",
    "from tqdm import tqdm # progress bar\n",
    "from pprint import pprint # pretty print (useful for a more readable print of objects like lists or dictionaries)\n",
    "from IPython.display import clear_output # to clear the output of the notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2 as cv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROL\n",
    "num_channels = 1\n",
    "SIZE = (32,32)\n",
    "FOLDER = 'training'\n",
    "model_name = 'models/lane_keeper_ahead.pt'\n",
    "onnx_lane_keeper_path = \"models/lane_keeper_ahead.onnx\"\n",
    "max_load = 500_000 #note: it will be ~50% more since training points with pure road gets flipped with inverted labels\n",
    "frames = np.load(FOLDER+'/frames.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Net and create Detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NETWORK ARCHITECTURE\n",
    "# #very good\n",
    "# class LaneKeeperAhead(nn.Module):\n",
    "#     def __init__(self, out_dim=4, channels=1): \n",
    "#         super().__init__()\n",
    "#         ### Convoluational layers\n",
    "#         self.conv = nn.Sequential( #in = (SIZE)\n",
    "#             nn.Conv2d(channels, 8, kernel_size=5, stride=1), #out = 30\n",
    "#             nn.ReLU(True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2), #out=15\n",
    "#             nn.BatchNorm2d(8),\n",
    "#             nn.Conv2d(8, 4, kernel_size=5, stride=1), #out = 12\n",
    "#             nn.ReLU(True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=1), #out=11\n",
    "#             # nn.BatchNorm2d(4),\n",
    "#             nn.Conv2d(4, 4, kernel_size=6, stride=1), #out = 6\n",
    "#             nn.ReLU(True),\n",
    "#         )\n",
    "#         self.flat = nn.Flatten()\n",
    "#         ### Linear sections\n",
    "#         self.lin = nn.Sequential(\n",
    "#             # First linear layer\n",
    "#             nn.Linear(in_features=4*4*4, out_features=16),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Linear(in_features=16, out_features=out_dim),\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         x = self.flat(x)\n",
    "#         x = self.lin(x)\n",
    "#         return x\n",
    "\n",
    "# lane_keeper_ahead = LaneKeeperAhead(out_dim=2,channels=num_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK ARCHITECTURE\n",
    "\n",
    "class LaneKeeperAhead(nn.Module):\n",
    "    def __init__(self, out_dim=4, channels=1): \n",
    "        super().__init__()\n",
    "        ### Convoluational layers\n",
    "        prob = 0.3\n",
    "        self.conv = nn.Sequential( #in = (SIZE)\n",
    "            nn.Conv2d(channels, 4, kernel_size=5, stride=1), #out = 28\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=prob),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), #out=14\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.Dropout(p=prob),\n",
    "            nn.Conv2d(4, 4, kernel_size=5, stride=1), #out = 10\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=prob),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), #out=5\n",
    "            nn.Dropout(p=prob),\n",
    "            nn.Conv2d(4, 32, kernel_size=5, stride=1), #out = 1\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.flat = nn.Flatten()\n",
    "        ### Linear sections\n",
    "        self.lin = nn.Sequential(\n",
    "            #normalize\n",
    "            # nn.BatchNorm1d(3*3*4),\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=1*1*32, out_features=16),\n",
    "            nn.ReLU(True),\n",
    "            # nn.Tanh(),\n",
    "            nn.Linear(in_features=16, out_features=out_dim),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "lane_keeper_ahead = LaneKeeperAhead(out_dim=1,channels=num_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32, 32])\n",
      "out shape: torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# TEST NET INPUTS/OUTPUTS\n",
    "#show the image with opencv\n",
    "img = frames[0]\n",
    "img = cv.resize(img, SIZE)\n",
    "if num_channels == 1:\n",
    "    # img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "#convert to tensor\n",
    "img = torch.from_numpy(img).float()\n",
    "img = img.permute(2,0,1)\n",
    "#add dimension\n",
    "img = img.unsqueeze(0).to(device)\n",
    "print(img.shape)\n",
    "\n",
    "lane_keeper_ahead.eval()\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    output = lane_keeper_ahead(img)\n",
    "    print(f'out shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG LOADER AND AUGMENTATION\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "from time import time, sleep\n",
    "\n",
    "\n",
    "def load_and_augment_img(img, folder='training_imgs'):\n",
    "    #convert to gray\n",
    "    img = cv.resize(img, (4*SIZE[1], 4*SIZE[0]))\n",
    "\n",
    "    # img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    #create random ellipses to simulate light from the sun\n",
    "    light = np.zeros(img.shape, dtype=np.uint8)\n",
    "    #add ellipses\n",
    "    for j in range(2):\n",
    "        cent = (randint(0, img.shape[0]), randint(0, img.shape[1]))\n",
    "        axes_length = (randint(10//4, 50//4), randint(50//4, 300//4))\n",
    "        angle = randint(0, 360)\n",
    "        light = cv.ellipse(light, cent, axes_length, angle, 0, 360, 255, -1)\n",
    "    #create an image of random white and black pixels\n",
    "    light = cv.blur(light, (50,50))\n",
    "    noise = randint(0, 2, size=img.shape, dtype=np.uint8)*255\n",
    "    light = cv.subtract(light, noise)\n",
    "    light = np.clip(light, 0, 51)\n",
    "    light *= 5\n",
    "    #add light to the image\n",
    "    img = cv.add(img, light)\n",
    "\n",
    "    # cv.imshow('light', light)\n",
    "    # if cv.waitKey(0) == ord('q'):\n",
    "    #     break\n",
    "\n",
    "    #blur the image\n",
    "    img = cv.blur(img, (randint(1, 5), randint(1, 5)))\n",
    "\n",
    "    # cut the top third of the image, let it 640x320\n",
    "    img = img[int(img.shape[0]/3):,:] ################################# /3\n",
    "    # assert img.shape == (320,640), f'img shape cut = {img.shape}'\n",
    "\n",
    "    #edges\n",
    "    img = cv.resize(img, (2*SIZE[1], 2*SIZE[0]))\n",
    "\n",
    "    r = randint(0, 5)\n",
    "    if r == 0:\n",
    "        #dilate\n",
    "        kernel = np.ones((randint(1, 5), randint(1, 5)), np.uint8)\n",
    "        img = cv.dilate(img, kernel, iterations=1)\n",
    "    elif r == 1:\n",
    "        #erode\n",
    "        kernel = np.ones((randint(1, 5), randint(1, 5)), np.uint8)\n",
    "        img = cv.erode(img, kernel, iterations=1)\n",
    "\n",
    "\n",
    "    #edges    \n",
    "    img = cv.Canny(img, 100, 200)\n",
    "\n",
    "    #blur\n",
    "    img = cv.blur(img, (3,3))\n",
    "\n",
    "    #resize \n",
    "    img = cv.resize(img, SIZE)\n",
    "\n",
    "    # #get max brightness\n",
    "    # max_brightness = np.max(img)\n",
    "    # ratio = 255.0/max_brightness\n",
    "    # #normalize\n",
    "    # img = (img*ratio).astype(np.uint8)\n",
    "\n",
    "    #add random tilt\n",
    "    max_offset = 3\n",
    "    offset = randint(-max_offset, max_offset)\n",
    "    img = np.roll(img, offset, axis=0)\n",
    "    if offset > 0:\n",
    "        img[:offset, :] = 0 #randint(0,255)\n",
    "    elif offset < 0:\n",
    "        img[offset:, :] = 0 # randint(0,255)\n",
    "    \n",
    "    # #add salt and pepper noise\n",
    "    # sp_noise = randint(0, 4, size=img.shape, dtype=np.uint8)\n",
    "    # sp_noise = np.where(sp_noise == 0, np.zeros_like(img), 255*np.ones_like(img))\n",
    "    # # img = cv.bitwise_xor(img, sp_noise)\n",
    "\n",
    "\n",
    "    # #reduce contrast\n",
    "    # const = np.random.uniform(0.1,0.8)\n",
    "    # # if np.random.uniform() > .5:\n",
    "    # #     const = const*0.2\n",
    "    # img = 127*(1-const) + img*const\n",
    "    # img = img.astype(np.uint8)\n",
    "\n",
    "    #add noise \n",
    "    std = 80\n",
    "    std = randint(1, std)\n",
    "    noisem = randint(0, std, img.shape, dtype=np.uint8)\n",
    "    img = cv.subtract(img, noisem)\n",
    "    noisep = randint(0, std, img.shape, dtype=np.uint8)\n",
    "    img = cv.add(img, noisep)\n",
    "\n",
    "    # #add random brightness\n",
    "    # max_brightness = 60\n",
    "    # brightness = randint(-max_brightness, max_brightness)\n",
    "    # if brightness > 0:\n",
    "    #     img = cv.add(img, brightness)\n",
    "    # elif brightness < 0:\n",
    "    #     img = cv.subtract(img, -brightness)\n",
    "\n",
    "    # #blur \n",
    "    # img = cv.blur(img, (randint(1,3),randint(1,3)))\n",
    "\n",
    "    # # invert color\n",
    "    # if np.random.uniform(0, 1) > 0.6:\n",
    "    #     img = cv.bitwise_not(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "cv.namedWindow('img', cv.WINDOW_NORMAL)\n",
    "# cv.setWindowProperty('img', cv.WND_PROP_FULLSCREEN, cv.WINDOW_FULLSCREEN)\n",
    "\n",
    "for i in range(5000):\n",
    "    img = frames[i]\n",
    "    img = load_and_augment_img(img)\n",
    "    cv.imshow('img', img)\n",
    "    key = cv.waitKey(100)\n",
    "    if key == ord('q') or key == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET CLASS\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None, max_load=1000, channels=3):\n",
    "        self.transform = transform\n",
    "        self.folder = folder\n",
    "        self.data = []\n",
    "        self.channels = channels\n",
    "\n",
    "        #load all the numpy files\n",
    "        print('loading data...')\n",
    "        speed_log = np.load(FOLDER+'/speed_log.npy')\n",
    "        steer_log = np.load(FOLDER+'/steer_log.npy')\n",
    "        he_log = np.load(FOLDER+'/he_log.npy')\n",
    "        seq_he_log = np.load(FOLDER+'/seq_he_log.npy')\n",
    "        seq_rel_angles_log = np.load(FOLDER+'/seq_rel_angles_log.npy')\n",
    "        print('data loaded')\n",
    "        print('uncompressing frames...')\n",
    "        frames = np.load(FOLDER+'/frames.npy')\n",
    "        print('frames uncompressed')\n",
    "\n",
    "        #check all the data is the same length\n",
    "        assert len(speed_log) == len(steer_log) == len(he_log) == len(seq_he_log) == len(seq_rel_angles_log) == len(frames) , f'{len(speed_log)}, {len(steer_log)}, {len(he_log)}, {len(seq_he_log)}, {len(seq_rel_angles_log)}, {len(frames)}'\n",
    "        total_datapoints = len(frames)\n",
    "\n",
    "\n",
    "        max_load = min(max_load, total_datapoints)\n",
    "        # self.all_imgs = torch.zeros((2*max_load, SIZE[1], SIZE[0], channels), dtype=torch.uint8) #adding flipped img\n",
    "        self.all_imgs = torch.zeros((max_load, SIZE[1], SIZE[0], channels), dtype=torch.uint8)\n",
    "\n",
    "        road_labels = []\n",
    "\n",
    "        cv.namedWindow('img', cv.WINDOW_NORMAL)\n",
    "        # cv.setWindowProperty('img', cv.WND_PROP_FULLSCREEN, cv.WINDOW_FULLSCREEN)\n",
    "        road_idx = 0\n",
    "        all_img_idx = 0\n",
    "        for i in tqdm(range(max_load)):\n",
    "\n",
    "            #label\n",
    "            speed = speed_log[i]\n",
    "            steer = steer_log[i]\n",
    "            he = he_log[i]\n",
    "            seq_he = seq_he_log[i]\n",
    "            seq_rel_angles = seq_rel_angles_log[i]\n",
    "\n",
    "            #keep only info related to the lane, discard distance from stop line \n",
    "            sample = [he] #e2=lateral error, e3=yaw error point ahead, curvature\n",
    "            reg_label = np.array([float(s) for s in sample], dtype=np.float32)\n",
    "\n",
    "            #img \n",
    "            img = frames[i]\n",
    "\n",
    "            img = load_and_augment_img(img)\n",
    "            # cv.putText(img, f'{reg_label[0]*10.0}', (5,5), cv.FONT_HERSHEY_SIMPLEX, 0.4,255, 1)\n",
    "            MAX_SHOW = 1000\n",
    "            max_show = MAX_SHOW\n",
    "            if i < max_show:\n",
    "                cv.imshow('img', img)\n",
    "                key = cv.waitKey(1)\n",
    "                if i == max_show-1:\n",
    "                    cv.destroyAllWindows()\n",
    "            #add a dimension to the image\n",
    "            img = img[:, :,np.newaxis]\n",
    "            self.all_imgs[all_img_idx] = torch.from_numpy(img)\n",
    "            self.data.append(reg_label)\n",
    "            all_img_idx += 1\n",
    "\n",
    "        self.data = np.array(self.data)\n",
    "        print(f'\\nall imgs: {self.all_imgs.shape}')\n",
    "        print(f'data: {self.data.shape}')\n",
    "        del road_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # The length of the dataset is simply the length of the self.data list\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # img = read_image(os.path.join(self.folder, f'img_{idx+1}.png'))\n",
    "        # img = img.float()\n",
    "        img = self.all_imgs[idx]\n",
    "        img = img.permute(2, 0, 1).float()\n",
    "        value = self.data[idx]\n",
    "        return img, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "data loaded\n",
      "uncompressing frames...\n",
      "frames uncompressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4362/4362 [00:08<00:00, 501.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "all imgs: torch.Size([4362, 32, 32, 1])\n",
      "data: (4362, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#create dataset #takes a long time but then training is faster\n",
    "train_dataset = MyDataset('training_imgs', max_load=max_load, channels=num_channels)\n",
    "#split dataset into train and val\n",
    "train_size = int(0.9*len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8192, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3925, 1, 32, 32])\n",
      "torch.Size([3925, 1])\n"
     ]
    }
   ],
   "source": [
    "#test dataloader\n",
    "sample = next(iter(train_dataloader))\n",
    "print(sample[0].shape)\n",
    "print(sample[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING FUNCTION\n",
    "def train_epoch(model, dataloader, regr_loss_fn, optimizer, L1_lambda=0.0, L2_lambda=0.0,  device=device):\n",
    "    # Set the model to training mode\n",
    "    model.train() #train\n",
    "    # Initialize the loss\n",
    "    # err_losses2 = []\n",
    "    err_losses3 = []\n",
    "    # curv_losses = []\n",
    "\n",
    "    # Loop over the training batches\n",
    "    for (input, regr_label) in tqdm(dataloader):\n",
    "        # Move the input and target data to the selected device\n",
    "        input, regr_label =input.to(device), regr_label.to(device)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the output\n",
    "        output = model(input)\n",
    "\n",
    "        #regression\n",
    "        # err2 = output[:, 0]\n",
    "        err3 = output[:, 0]\n",
    "        # curv_out = output[:, 2]\n",
    "\n",
    "        # err2_label = regr_label[:, 0]\n",
    "        err3_label = regr_label[:, 0]\n",
    "        # curv_label = regr_label[:, 2]\n",
    "\n",
    "        # Compute the losses\n",
    "        # err_loss2 = 1.0*regr_loss_fn(err2, err2_label)\n",
    "        err_loss3 = 1.0*regr_loss_fn(err3, err3_label)\n",
    "        # curv_loss = 1.0*regr_loss_fn(curv_out, curv_label)\n",
    "\n",
    "        #L1 regularization\n",
    "        L1_norm = sum(p.abs().sum() for p in model.conv.parameters())\n",
    "        L1_loss = L1_lambda * L1_norm \n",
    "        #L2 regularization\n",
    "        L2_norm = sum(p.pow(2).sum() for p in model.conv.parameters())\n",
    "        L2_loss = L2_lambda * L2_norm\n",
    "\n",
    "        loss = err_loss3 + L1_loss + L2_loss\n",
    "\n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #batch loss\n",
    "        # err_losses2.append(err_loss2.detach().cpu().numpy())\n",
    "        err_losses3.append(err_loss3.detach().cpu().numpy())\n",
    "        # curv_losses.append(curv_loss.detach().cpu().numpy())\n",
    "\n",
    "    # Return the average training loss\n",
    "    # err_loss2 = np.mean(err_losses2)\n",
    "    err_loss3 = np.mean(err_losses3)\n",
    "    # curv_loss = np.mean(curv_losses)\n",
    "    return err_loss3\n",
    "\n",
    "    # VALIDATION FUNCTION\n",
    "def val_epoch(lane_keeper_ahead, val_dataloader, regr_loss_fn, device=device):\n",
    "    lane_keeper_ahead.eval()\n",
    "    err_losses3 = []\n",
    "    # err_losses2 = []\n",
    "    # curv_losses = []\n",
    "    for (input, regr_label) in tqdm(val_dataloader):\n",
    "        input, regr_label =input.to(device), regr_label.to(device)\n",
    "        output = lane_keeper_ahead(input)\n",
    "\n",
    "        regr_out = output\n",
    "        # err2 = regr_out[:, 0]\n",
    "        err3 = regr_out[:, 0]\n",
    "        # curv_out = regr_out[:, 2]\n",
    "\n",
    "        # err2_label = regr_label[:, 0]\n",
    "        err3_label = regr_label[:, 0]\n",
    "        # curv_label = regr_label[:, 2]\n",
    "\n",
    "        err_loss3 = 1.0*regr_loss_fn(err3, err3_label)\n",
    "\n",
    "        # err_losses2.append(err_loss2.detach().cpu().numpy())\n",
    "        err_losses3.append(err_loss3.detach().cpu().numpy())\n",
    "        # curv_losses.append(curv_loss.detach().cpu().numpy())\n",
    "    return np.mean(err_losses3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  500/500,  loss = MSELoss() \n",
      "yaw_err_loss3: 0.0263,   Val: 0.0329, best_val: 0.0286\n"
     ]
    }
   ],
   "source": [
    "# TRAINING \n",
    "#parameters\n",
    "lr = 0.003 #0.005\n",
    "epochs = 500 #500\n",
    "#regularization is applied only to convolutional section, add weight decay to apply it to all layers\n",
    "L1_lambda = 1e-4 #9e-4\n",
    "L2_lambda = 1e-2 #1e-2\n",
    "optimizer = torch.optim.Adam(lane_keeper_ahead.parameters(), lr=lr, weight_decay=9e-5) #wd = 2e-3# 3e-5\n",
    "regr_loss_fn1 = nn.MSELoss() #before epochs/2\n",
    "regr_loss_fn2 = nn.MSELoss() #after epochs/2 for finetuning\n",
    "\n",
    "best_val = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    try:\n",
    "    # if True:\n",
    "        regr_loss_fn = regr_loss_fn1 if epoch < epochs//2 else regr_loss_fn2\n",
    "        err_loss3 = train_epoch(lane_keeper_ahead, train_dataloader, regr_loss_fn, optimizer, L1_lambda, L2_lambda, device)\n",
    "        val_loss3 = val_epoch(lane_keeper_ahead, val_dataloader, regr_loss_fn, device)\n",
    "        clear_output(wait=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        torch.cuda.empty_cache()\n",
    "        continue\n",
    "    if val_loss3 < best_val:\n",
    "        best_val = val_loss3\n",
    "        torch.save(lane_keeper_ahead.state_dict(), model_name)\n",
    "        print(\"model saved\")\n",
    "    \n",
    "    print(f\"Epoch  {epoch+1}/{epochs},  loss = {regr_loss_fn} \\nyaw_err_loss3: {err_loss3:.4f},   Val: {val_loss3:.4f}, best_val: {best_val:.4f}\")\n",
    "    # print(f\"lat_err_loss2: {err_loss2:.4f},   Val: {val_loss2:.4f}\")\n",
    "    # print(f\"curv_loss: {curv_loss}\")\n",
    "\n",
    "#Note: sweet spot for training is around 0.016 -> 0.020, also note that training can get stuck, and loss can start improving randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 244.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yaw_err3_loss: 0.030938416719436646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE ON TEST SET (UNSEEN DATA)\n",
    "lane_keeper_ahead.load_state_dict(torch.load(model_name))\n",
    "err_loss3 = val_epoch(lane_keeper_ahead, val_dataloader, regr_loss_fn, device)\n",
    "\n",
    "# print(f\"lateral_err2_loss: {err_loss2}\")\n",
    "print(f\"yaw_err3_loss: {err_loss3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 5, 5)\n",
      "(4, 4, 5, 5)\n",
      "(32, 4, 5, 5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x144 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# VISUALIZE CONVOLUTIONAL FILTERS\n",
    "conv_layers = []\n",
    "children = list(lane_keeper_ahead.children())\n",
    "for i in range(len(children)):\n",
    "    if isinstance(children[i], nn.Conv2d):\n",
    "        conv_layers.append(children[i])\n",
    "    elif isinstance(children[i], nn.Sequential):\n",
    "        for child in children[i].children():\n",
    "            if isinstance(child, nn.Conv2d):\n",
    "                conv_layers.append(child)\n",
    "\n",
    "c0 = conv_layers[0].weight.data.cpu().numpy()\n",
    "c1 = conv_layers[1].weight.data.cpu().numpy()\n",
    "c2 = conv_layers[2].weight.data.cpu().numpy()\n",
    "\n",
    "def plot_nchw_data(data, h_num, v_num, title, size=(10, 10)):\n",
    "    fig, axs = plt.subplots(h_num, v_num, figsize=size)\n",
    "    shape = data.shape\n",
    "    data = data.reshape(shape[0]*shape[1], shape[2], shape[3])\n",
    "    for idx, ax in enumerate(axs.flatten()):\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if idx < len(data):\n",
    "            ax.imshow(data[idx,:,:], cmap='gray')\n",
    "    plt.suptitle(title)\n",
    "    #plt.tight_layout(rect=[0, 0, 1, 0.97], h_pad=0, w_pad=0)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "# fig0 = plot_nchw_data(c0, 4, 4, 'conv0')\n",
    "print(c0.shape)\n",
    "print(c1.shape)\n",
    "print(c2.shape)\n",
    "\n",
    "fig0 = plot_nchw_data(c0, 1, 4, 'conv0', size=(8,2))\n",
    "\n",
    "fig1 = plot_nchw_data(c1, 4, 4, 'conv1', size=(5,5)) \n",
    "\n",
    "fig2 = plot_nchw_data(c2, 8, 8, 'conv2', size=(10,10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LaneKeeperAhead(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Conv2d(4, 4, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Dropout(p=0.3, inplace=False)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Dropout(p=0.3, inplace=False)\n",
       "    (11): Conv2d(4, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "  )\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (lin): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT TO ONNX MODEL FOR OPENCV\n",
    "lane_keeper_ahead.load_state_dict(torch.load(model_name))\n",
    "\n",
    "#save the model so that opencv can load it\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "device = torch.device('cpu')\n",
    "lane_keeper_ahead.to(device)\n",
    "\n",
    "# set the model to inference mode\n",
    "lane_keeper_ahead.eval()\n",
    "\n",
    "# Create some sample input in the shape this model expects \n",
    "# This is needed because the convertion forward pass the network once \n",
    "dummy_input = torch.randn(1, num_channels, SIZE[1], SIZE[0])\n",
    "torch.onnx.export(lane_keeper_ahead, dummy_input, onnx_lane_keeper_path, verbose=True)\n",
    "\n",
    "clear_output(wait=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "lane_keeper_ahead.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
