{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px # this is another plotting library for interactive plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, manifold # we will use the metrics and manifold learning modules from scikit-learn\n",
    "from pathlib import Path # to interact with file paths\n",
    "from PIL import Image # to interact with images\n",
    "from tqdm import tqdm # progress bar\n",
    "from pprint import pprint # pretty print (useful for a more readable print of objects like lists or dictionaries)\n",
    "from IPython.display import clear_output # to clear the output of the notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2 as cv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device = {device}')\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROL\n",
    "LOTS_OF_GRAM = True\n",
    "num_channels = 1\n",
    "SIZE = (32,32)\n",
    "FOLDER = 'Simulator/training'\n",
    "MODEL_FOLDER = 'Simulator/models'\n",
    "model_name = MODEL_FOLDER + '/lane_keeper.pt'\n",
    "onnx_lane_keeper_path = MODEL_FOLDER + '/lane_keeper.onnx'\n",
    "max_load = 500_000 #note: it will be ~50% more since training points with pure road gets flipped with inverted labels\n",
    "frames = np.load(FOLDER+'/frames.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Net and create Detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NETWORK ARCHITECTURE\n",
    "# #very good\n",
    "# class LaneKeeperAhead(nn.Module):\n",
    "#     def __init__(self, out_dim=4, channels=1): \n",
    "#         super().__init__()\n",
    "#         ### Convoluational layers\n",
    "#         self.conv = nn.Sequential( #in = (SIZE)\n",
    "#             nn.Conv2d(channels, 8, kernel_size=5, stride=1), #out = 30\n",
    "#             nn.ReLU(True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2), #out=15\n",
    "#             nn.BatchNorm2d(8),\n",
    "#             nn.Conv2d(8, 4, kernel_size=5, stride=1), #out = 12\n",
    "#             nn.ReLU(True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=1), #out=11\n",
    "#             # nn.BatchNorm2d(4),\n",
    "#             nn.Conv2d(4, 4, kernel_size=6, stride=1), #out = 6\n",
    "#             nn.ReLU(True),\n",
    "#         )\n",
    "#         self.flat = nn.Flatten()\n",
    "#         ### Linear sections\n",
    "#         self.lin = nn.Sequential(\n",
    "#             # First linear layer\n",
    "#             nn.Linear(in_features=4*4*4, out_features=16),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Linear(in_features=16, out_features=out_dim),\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         x = self.flat(x)\n",
    "#         x = self.lin(x)\n",
    "#         return x\n",
    "\n",
    "# lane_keeper_ahead = LaneKeeperAhead(out_dim=2,channels=num_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK ARCHITECTURE\n",
    "\n",
    "class LaneKeeperAhead(nn.Module):\n",
    "    def __init__(self, out_dim=4, channels=1): \n",
    "        super().__init__()\n",
    "        ### Convoluational layers\n",
    "        prob = 0.3\n",
    "        self.conv = nn.Sequential( #in = (SIZE)\n",
    "            nn.Conv2d(channels, 4, kernel_size=5, stride=1), #out = 28v\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=prob),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), #out=14\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.Dropout(p=prob),\n",
    "            nn.Conv2d(4, 4, kernel_size=5, stride=1), #out = 10\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=prob),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), #out=5\n",
    "            nn.Dropout(p=prob),\n",
    "            nn.Conv2d(4, 32, kernel_size=5, stride=1), #out = 1\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.flat = nn.Flatten()\n",
    "        ### Linear sections\n",
    "        self.lin = nn.Sequential(\n",
    "            #normalize\n",
    "            # nn.BatchNorm1d(3*3*4),\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=1*1*32, out_features=16),\n",
    "            nn.ReLU(True),\n",
    "            # nn.Tanh(),\n",
    "            nn.Linear(in_features=16, out_features=out_dim),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "lane_keeper_ahead = LaneKeeperAhead(out_dim=1,channels=num_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPOUT_PROB = 0.3\n",
    "# DEFAULT_CONV_LAYERS = nn.Sequential( #in = 32x32\n",
    "#             nn.Conv2d(1, 4, 5, 1), #out = 28\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(p=DROPOUT_PROB),\n",
    "#             nn.MaxPool2d(2, 2), #out=14\n",
    "#             nn.BatchNorm2d(4),\n",
    "#             nn.Dropout(p=DROPOUT_PROB),\n",
    "#             nn.Conv2d(4, 4, 5, 1), #out = 10\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(p=DROPOUT_PROB),\n",
    "#             nn.MaxPool2d(2, 2), #out=5\n",
    "#             nn.Dropout(p=DROPOUT_PROB),\n",
    "#             nn.Conv2d(4, 32, 5, 1), #out = 1\n",
    "#             nn.ReLU(True),\n",
    "#         )\n",
    "# DEFAULT_FC_LAYERS = nn.Sequential(\n",
    "#             nn.Linear(1*1*32, 16),\n",
    "#             nn.ReLU(True),\n",
    "#             # nn.Tanh(),\n",
    "#             nn.Linear(16, 1),\n",
    "#         )\n",
    "\n",
    "# IN, OUT, CONV_LAYERS, FC_LAYERS, DROPOUT = 'IN', 'OUT', 'CONV_LAYERS', 'FC_LAYERS', 'DROPOUT'\n",
    "\n",
    "# NET_PARAMS = {IN:32, OUT:1, CONV_LAYERS:DEFAULT_CONV_LAYERS, FC_LAYERS:DEFAULT_FC_LAYERS, DROPOUT:DROPOUT_PROB}\n",
    "\n",
    "\n",
    "# class HEstimator(nn.Module):\n",
    "#     def __init__(self, net_params=NET_PARAMS):\n",
    "#         super().__init__()\n",
    "#         self.conv = net_params[CONV_LAYERS]\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.lin = net_params[FC_LAYERS]\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.lin(x)\n",
    "#         return x\n",
    "\n",
    "# lane_keeper_ahead = HEstimator(NET_PARAMS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST NET INPUTS/OUTPUTS\n",
    "#show the image with opencv\n",
    "img = frames[0]\n",
    "img = cv.resize(img, SIZE)\n",
    "if num_channels == 1:\n",
    "    # img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "#convert to tensor\n",
    "img = torch.from_numpy(img).float()\n",
    "img = img.permute(2,0,1)\n",
    "#add dimension\n",
    "img = img.unsqueeze(0)\n",
    "#send to device\n",
    "img = img.to(device)\n",
    "print(f'input shape = {img.shape}')\n",
    "\n",
    "lane_keeper_ahead.eval()\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    output = lane_keeper_ahead(img)\n",
    "    print(f'out shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG LOADER AND AUGMENTATION\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "from time import time, sleep\n",
    "\n",
    "\n",
    "def load_and_augment_img(img, folder='training_imgs'):\n",
    "    #convert to gray\n",
    "    img = cv.resize(img, (4*SIZE[1], 4*SIZE[0]))\n",
    "\n",
    "    # img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    #create random ellipses to simulate light from the sun\n",
    "    light = np.zeros(img.shape, dtype=np.uint8)\n",
    "    #add ellipses\n",
    "    for j in range(2):\n",
    "        cent = (randint(0, img.shape[0]), randint(0, img.shape[1]))\n",
    "        axes_length = (randint(10//4, 50//4), randint(50//4, 300//4))\n",
    "        angle = randint(0, 360)\n",
    "        light = cv.ellipse(light, cent, axes_length, angle, 0, 360, 255, -1)\n",
    "    #create an image of random white and black pixels\n",
    "    light = cv.blur(light, (50,50))\n",
    "    noise = randint(0, 2, size=img.shape, dtype=np.uint8)*255\n",
    "    light = cv.subtract(light, noise)\n",
    "    light = np.clip(light, 0, 51)\n",
    "    light *= 5\n",
    "    #add light to the image\n",
    "    img = cv.add(img, light)\n",
    "\n",
    "    # cv.imshow('light', light)\n",
    "    # if cv.waitKey(0) == ord('q'):\n",
    "    #     break\n",
    "\n",
    "    r = randint(0, 5)\n",
    "    if r == 0:\n",
    "        #dilate\n",
    "        kernel = np.ones((randint(1, 5), randint(1, 5)), np.uint8)\n",
    "        img = cv.dilate(img, kernel, iterations=1)\n",
    "    elif r == 1:\n",
    "        #erode\n",
    "        kernel = np.ones((randint(1, 5), randint(1, 5)), np.uint8)\n",
    "        img = cv.erode(img, kernel, iterations=1)\n",
    "\n",
    "    #blur the image\n",
    "    img = cv.blur(img, (randint(1, 5), randint(1, 5)))\n",
    "\n",
    "    # cut the top third of the image, let it 640x320\n",
    "    img = img[int(img.shape[0]/3):,:] ################################# /3\n",
    "    # assert img.shape == (320,640), f'img shape cut = {img.shape}'\n",
    "\n",
    "    #edges\n",
    "    img = cv.resize(img, (2*SIZE[1], 2*SIZE[0]))\n",
    "\n",
    "\n",
    "\n",
    "    #edges    \n",
    "    img = cv.Canny(img, 100, 200)\n",
    "\n",
    "    #blur\n",
    "    img = cv.blur(img, (3,3))\n",
    "\n",
    "    #resize \n",
    "    img = cv.resize(img, SIZE)\n",
    "\n",
    "    # #get max brightness\n",
    "    # max_brightness = np.max(img)\n",
    "    # ratio = 255.0/max_brightness\n",
    "    # #normalize\n",
    "    # img = (img*ratio).astype(np.uint8)\n",
    "\n",
    "    #add random tilt\n",
    "    max_offset = 3\n",
    "    offset = randint(-max_offset, max_offset)\n",
    "    img = np.roll(img, offset, axis=0)\n",
    "    if offset > 0:\n",
    "        img[:offset, :] = 0 #randint(0,255)\n",
    "    elif offset < 0:\n",
    "        img[offset:, :] = 0 # randint(0,255)\n",
    "    \n",
    "    # #add salt and pepper noise\n",
    "    # sp_noise = randint(0, 4, size=img.shape, dtype=np.uint8)\n",
    "    # sp_noise = np.where(sp_noise == 0, np.zeros_like(img), 255*np.ones_like(img))\n",
    "    # # img = cv.bitwise_xor(img, sp_noise)\n",
    "\n",
    "\n",
    "    # #reduce contrast\n",
    "    # const = np.random.uniform(0.1,0.8)\n",
    "    # # if np.random.uniform() > .5:\n",
    "    # #     const = const*0.2\n",
    "    # img = 127*(1-const) + img*const\n",
    "    # img = img.astype(np.uint8)\n",
    "\n",
    "    #add noise \n",
    "    std = 80\n",
    "    std = randint(1, std)\n",
    "    noisem = randint(0, std, img.shape, dtype=np.uint8)\n",
    "    img = cv.subtract(img, noisem)\n",
    "    noisep = randint(0, std, img.shape, dtype=np.uint8)\n",
    "    img = cv.add(img, noisep)\n",
    "\n",
    "    # #add random brightness\n",
    "    # max_brightness = 60\n",
    "    # brightness = randint(-max_brightness, max_brightness)\n",
    "    # if brightness > 0:\n",
    "    #     img = cv.add(img, brightness)\n",
    "    # elif brightness < 0:\n",
    "    #     img = cv.subtract(img, -brightness)\n",
    "\n",
    "    # #blur \n",
    "    # img = cv.blur(img, (randint(1,3),randint(1,3)))\n",
    "\n",
    "    # # invert color\n",
    "    # if np.random.uniform(0, 1) > 0.6:\n",
    "    #     img = cv.bitwise_not(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "cv.namedWindow('img', cv.WINDOW_NORMAL)\n",
    "# cv.setWindowProperty('img', cv.WND_PROP_FULLSCREEN, cv.WINDOW_FULLSCREEN)\n",
    "\n",
    "for i in range(5000):\n",
    "    img = frames[i]\n",
    "    img = load_and_augment_img(img)\n",
    "    cv.imshow('img', img)\n",
    "    key = cv.waitKey(100)\n",
    "    if key == ord('q') or key == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET CLASS\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None, max_load=1000, channels=3):\n",
    "        self.transform = transform\n",
    "        self.folder = folder\n",
    "        self.data = []\n",
    "        self.channels = channels\n",
    "\n",
    "        #load all the numpy files\n",
    "        print('loading data...')\n",
    "        speed_log = np.load(FOLDER+'/speed_log.npy')\n",
    "        steer_log = np.load(FOLDER+'/steer_log.npy')\n",
    "        he_log = np.load(FOLDER+'/he_log.npy')\n",
    "        seq_he_log = np.load(FOLDER+'/seq_he_log.npy')\n",
    "        seq_rel_angles_log = np.load(FOLDER+'/seq_rel_angles_log.npy')\n",
    "        print('data loaded')\n",
    "        print('uncompressing frames...')\n",
    "        frames = np.load(FOLDER+'/frames.npy')\n",
    "        print('frames uncompressed')\n",
    "\n",
    "        #check all the data is the same length\n",
    "        assert len(speed_log) == len(steer_log) == len(he_log) == len(seq_he_log) == len(seq_rel_angles_log) == len(frames) , f'{len(speed_log)}, {len(steer_log)}, {len(he_log)}, {len(seq_he_log)}, {len(seq_rel_angles_log)}, {len(frames)}'\n",
    "        total_datapoints = len(frames)\n",
    "\n",
    "\n",
    "        max_load = min(max_load, total_datapoints)\n",
    "        # self.all_imgs = torch.zeros((2*max_load, SIZE[1], SIZE[0], channels), dtype=torch.uint8) #adding flipped img\n",
    "        self.all_imgs = torch.zeros((max_load, SIZE[1], SIZE[0], channels), dtype=torch.uint8)\n",
    "\n",
    "        road_labels = []\n",
    "\n",
    "        cv.namedWindow('img', cv.WINDOW_NORMAL)\n",
    "        # cv.setWindowProperty('img', cv.WND_PROP_FULLSCREEN, cv.WINDOW_FULLSCREEN)\n",
    "        road_idx = 0\n",
    "        all_img_idx = 0\n",
    "        for i in tqdm(range(max_load)):\n",
    "\n",
    "            #label\n",
    "            speed = speed_log[i]\n",
    "            steer = steer_log[i]\n",
    "            he = he_log[i]\n",
    "            seq_he = seq_he_log[i]\n",
    "            seq_rel_angles = seq_rel_angles_log[i]\n",
    "\n",
    "            #keep only info related to the lane, discard distance from stop line \n",
    "            sample = [he] #e2=lateral error, e3=yaw error point ahead, curvature\n",
    "            reg_label = np.array([float(s) for s in sample], dtype=np.float32)\n",
    "\n",
    "            #img \n",
    "            img = frames[i]\n",
    "\n",
    "            img = load_and_augment_img(img)\n",
    "            # cv.putText(img, f'{reg_label[0]*10.0}', (5,5), cv.FONT_HERSHEY_SIMPLEX, 0.4,255, 1)\n",
    "            MAX_SHOW = 1000\n",
    "            max_show = MAX_SHOW\n",
    "            if i < max_show:\n",
    "                cv.imshow('img', img)\n",
    "                key = cv.waitKey(1)\n",
    "                if i == max_show-1:\n",
    "                    cv.destroyAllWindows()\n",
    "            #add a dimension to the image\n",
    "            img = img[:, :,np.newaxis]\n",
    "            self.all_imgs[all_img_idx] = torch.from_numpy(img)\n",
    "            self.data.append(reg_label)\n",
    "            all_img_idx += 1\n",
    "\n",
    "        self.data = np.array(self.data)\n",
    "        print(f'\\nall imgs: {self.all_imgs.shape}')\n",
    "        print(f'data: {self.data.shape}')\n",
    "\n",
    "        if LOTS_OF_GRAM:\n",
    "            self.data = torch.from_numpy(self.data)\n",
    "            self.data = self.data.to(device)\n",
    "            self.all_imgs = self.all_imgs.to(device)\n",
    "            \n",
    "        del road_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # The length of the dataset is simply the length of the self.data list\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.all_imgs[idx]\n",
    "        img = img.permute(2, 0, 1).float()\n",
    "        value = self.data[idx]\n",
    "        return img, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset #takes a long time but then training is faster\n",
    "train_dataset = MyDataset('training_imgs', max_load=max_load, channels=num_channels)\n",
    "#split dataset into train and val\n",
    "train_size = int(0.9*len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8*8192, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=100, shuffle=True)\n",
    "del frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test dataloader\n",
    "sample = next(iter(train_dataloader))\n",
    "print(sample[0].shape)\n",
    "print(sample[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING FUNCTION\n",
    "def train_epoch(model, dataloader, regr_loss_fn, optimizer, L1_lambda=0.0, L2_lambda=0.0,  device=device):\n",
    "    # Set the model to training mode\n",
    "    model.train() #train\n",
    "    # Initialize the loss\n",
    "    # err_losses2 = []\n",
    "    err_losses3 = []\n",
    "    # curv_losses = []\n",
    "\n",
    "    # Loop over the training batches\n",
    "    for (input, regr_label) in tqdm(dataloader):\n",
    "        # Move the input and target data to the selected device\n",
    "        if not LOTS_OF_GRAM:\n",
    "            input, regr_label =input.to(device), regr_label.to(device)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the output\n",
    "        output = model(input)\n",
    "\n",
    "        #regression\n",
    "        # err2 = output[:, 0]\n",
    "        err3 = output[:, 0]\n",
    "        # curv_out = output[:, 2]\n",
    "\n",
    "        # err2_label = regr_label[:, 0]\n",
    "        err3_label = regr_label[:, 0]\n",
    "        # curv_label = regr_label[:, 2]\n",
    "\n",
    "        # Compute the losses\n",
    "        # err_loss2 = 1.0*regr_loss_fn(err2, err2_label)\n",
    "        err_loss3 = 1.0*regr_loss_fn(err3, err3_label)\n",
    "        # curv_loss = 1.0*regr_loss_fn(curv_out, curv_label)\n",
    "\n",
    "        #L1 regularization\n",
    "        L1_norm = sum(p.abs().sum() for p in model.conv.parameters())\n",
    "        L1_loss = L1_lambda * L1_norm \n",
    "        #L2 regularization\n",
    "        L2_norm = sum(p.pow(2).sum() for p in model.conv.parameters())\n",
    "        L2_loss = L2_lambda * L2_norm\n",
    "\n",
    "        loss = err_loss3 + L1_loss + L2_loss\n",
    "\n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #batch loss\n",
    "        # err_losses2.append(err_loss2.detach().cpu().numpy())\n",
    "        err_losses3.append(err_loss3.detach().cpu().numpy())\n",
    "        # curv_losses.append(curv_loss.detach().cpu().numpy())\n",
    "\n",
    "    # Return the average training loss\n",
    "    # err_loss2 = np.mean(err_losses2)\n",
    "    err_loss3 = np.mean(err_losses3)\n",
    "    # curv_loss = np.mean(curv_losses)\n",
    "    return err_loss3\n",
    "\n",
    "    # VALIDATION FUNCTION\n",
    "def val_epoch(lane_keeper_ahead, val_dataloader, regr_loss_fn, device=device):\n",
    "    lane_keeper_ahead.eval()\n",
    "    err_losses3 = []\n",
    "    # err_losses2 = []\n",
    "    # curv_losses = []\n",
    "    for (input, regr_label) in tqdm(val_dataloader):\n",
    "        if not LOTS_OF_GRAM:\n",
    "            input, regr_label =input.to(device), regr_label.to(device)\n",
    "        output = lane_keeper_ahead(input)\n",
    "\n",
    "        regr_out = output\n",
    "        # err2 = regr_out[:, 0]\n",
    "        err3 = regr_out[:, 0]\n",
    "        # curv_out = regr_out[:, 2]\n",
    "\n",
    "        # err2_label = regr_label[:, 0]\n",
    "        err3_label = regr_label[:, 0]\n",
    "        # curv_label = regr_label[:, 2]\n",
    "\n",
    "        err_loss3 = 1.0*regr_loss_fn(err3, err3_label)\n",
    "\n",
    "        # err_losses2.append(err_loss2.detach().cpu().numpy())\n",
    "        err_losses3.append(err_loss3.detach().cpu().numpy())\n",
    "        # curv_losses.append(curv_loss.detach().cpu().numpy())\n",
    "    return np.mean(err_losses3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING \n",
    "#parameters\n",
    "lr = 0.003 #0.005\n",
    "epochs = 500 #500\n",
    "#regularization is applied only to convolutional section, add weight decay to apply it to all layers\n",
    "L1_lambda = 1e-4 #9e-4\n",
    "L2_lambda = 1e-2 #1e-2\n",
    "optimizer = torch.optim.Adam(lane_keeper_ahead.parameters(), lr=lr, weight_decay=9e-5) #wd = 2e-3# 3e-5\n",
    "regr_loss_fn1 = nn.MSELoss() #before epochs/2\n",
    "regr_loss_fn2 = nn.MSELoss() #after epochs/2 for finetuning\n",
    "\n",
    "best_val = 100\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    try:\n",
    "    # if True:\n",
    "        regr_loss_fn = regr_loss_fn1 if epoch < epochs//2 else regr_loss_fn2\n",
    "        err_loss3 = train_epoch(lane_keeper_ahead, train_dataloader, regr_loss_fn, optimizer, L1_lambda, L2_lambda, device)\n",
    "        val_loss3 = val_epoch(lane_keeper_ahead, val_dataloader, regr_loss_fn, device)\n",
    "        clear_output(wait=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        torch.cuda.empty_cache()\n",
    "        continue\n",
    "    if val_loss3 < best_val:\n",
    "        best_val = val_loss3\n",
    "        best_epoch = epoch\n",
    "        torch.save(lane_keeper_ahead.state_dict(), model_name)\n",
    "        print(\"model saved\")\n",
    "    \n",
    "    print(f\"Epoch  {epoch+1}/{epochs},  loss = {regr_loss_fn} \\nyaw_err_loss3: {err_loss3:.4f},   Val: {val_loss3:.4f}, best_val: {best_val:.4f}, best_epoch: {best_epoch}\")\n",
    "    # print(f\"lat_err_loss2: {err_loss2:.4f},   Val: {val_loss2:.4f}\")\n",
    "    # print(f\"curv_loss: {curv_loss}\")\n",
    "\n",
    "#Note: sweet spot for training is around 0.016 -> 0.020, also note that training can get stuck, and loss can start improving randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE ON TEST SET (UNSEEN DATA)\n",
    "lane_keeper_ahead.load_state_dict(torch.load(model_name))\n",
    "err_loss3 = val_epoch(lane_keeper_ahead, val_dataloader, regr_loss_fn, device)\n",
    "\n",
    "# print(f\"lateral_err2_loss: {err_loss2}\")\n",
    "print(f\"yaw_err3_loss: {err_loss3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE CONVOLUTIONAL FILTERS\n",
    "conv_layers = []\n",
    "children = list(lane_keeper_ahead.children())\n",
    "for i in range(len(children)):\n",
    "    if isinstance(children[i], nn.Conv2d):\n",
    "        conv_layers.append(children[i])\n",
    "    elif isinstance(children[i], nn.Sequential):\n",
    "        for child in children[i].children():\n",
    "            if isinstance(child, nn.Conv2d):\n",
    "                conv_layers.append(child)\n",
    "\n",
    "c0 = conv_layers[0].weight.data.cpu().numpy()\n",
    "c1 = conv_layers[1].weight.data.cpu().numpy()\n",
    "c2 = conv_layers[2].weight.data.cpu().numpy()\n",
    "\n",
    "def plot_nchw_data(data, h_num, v_num, title, size=(10, 10)):\n",
    "    fig, axs = plt.subplots(h_num, v_num, figsize=size)\n",
    "    shape = data.shape\n",
    "    data = data.reshape(shape[0]*shape[1], shape[2], shape[3])\n",
    "    for idx, ax in enumerate(axs.flatten()):\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if idx < len(data):\n",
    "            ax.imshow(data[idx,:,:], cmap='gray')\n",
    "    plt.suptitle(title)\n",
    "    #plt.tight_layout(rect=[0, 0, 1, 0.97], h_pad=0, w_pad=0)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "# fig0 = plot_nchw_data(c0, 4, 4, 'conv0')\n",
    "print(c0.shape)\n",
    "print(c1.shape)\n",
    "print(c2.shape)\n",
    "\n",
    "fig0 = plot_nchw_data(c0, 1, 4, 'conv0', size=(8,2))\n",
    "\n",
    "fig1 = plot_nchw_data(c1, 4, 4, 'conv1', size=(5,5)) \n",
    "\n",
    "fig2 = plot_nchw_data(c2, 8, 8, 'conv2', size=(10,10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT TO ONNX MODEL FOR OPENCV\n",
    "lane_keeper_ahead.load_state_dict(torch.load(model_name))\n",
    "\n",
    "#save the model so that opencv can load it\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "device = torch.device('cpu')\n",
    "lane_keeper_ahead.to(device)\n",
    "\n",
    "# set the model to inference mode\n",
    "lane_keeper_ahead.eval()\n",
    "\n",
    "# Create some sample input in the shape this model expects \n",
    "# This is needed because the convertion forward pass the network once \n",
    "dummy_input = torch.randn(1, num_channels, SIZE[1], SIZE[0])\n",
    "torch.onnx.export(lane_keeper_ahead, dummy_input, onnx_lane_keeper_path, verbose=True)\n",
    "\n",
    "clear_output(wait=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "lane_keeper_ahead.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ff087476d859467207b75b86d772837aefc8c57842a4549d55b8593c8b8ca04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
